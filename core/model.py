'''=================================================@Author ：Andy@Date   ：2020/7/8 11:57=================================================='''import datetimeimport osimport inspectimport pandas as pdimport numpy as npimport warningsimport timeimport pickleimport torchimport torch.nn as nnimport torch.nn.functional as Ffrom torch.utils.data import Dataset, DataLoader, TensorDatasetfrom core.log_config import loggerfrom core.getData import Datafrom fbprophet import Prophetfrom fbprophet.diagnostics import cross_validation, performance_metricsfrom pyecharts.charts import Pagefrom pyecharts.globals import CurrentConfigimport xgboost as xgbimport sklearnfrom sklearn.preprocessing import StandardScalerfrom .tools import RestDay, ProphetPlot, PlotXGB, PlotLSTMPROJECT_PATH = os.path.dirname(os.path.dirname(os.path.abspath(inspect.getframeinfo(inspect.currentframe()).filename)))CurrentConfig.ONLINE_HOST = os.path.join(PROJECT_PATH, "core/resources/assets/")warnings.filterwarnings("ignore")class ProphetModel():    def __init__(self, code, start, periods=30, metric = "mape", title = "趋势图", y = 'close', show_plot=True, show_point=True, show_cross=True, show_components=False):        self.code = code        self.start = start        self.periods = periods        self.show_plot = show_plot        self.show_point = show_point        self.show_cross = show_cross        self.show_components = show_components        self.title = title        self.metric = metric        self.y = y        self.forecast = None        self.prophet = None        self.future = None        self.prophet_plot = None        self.cv_data = None        self.performance = None        self.plot = None        self.point_plot = None        self.cross_plot = None        self.components = None    def init_data(self):        try:            data = Data(self.code, start=self.start)            data.get_query_history_k_data_plus()            data.query_history_k_data_plus.dropna(subset=['close'], inplace=True)            if data.query_history_k_data_plus.size == 0:                return None            return data.query_history_k_data_plus        except Exception as e:            logger.error(e)            return None    def fit(self,df, fit=True, growth='linear', changepoints=None, n_changepoints=25, changepoint_range=0.8, yearly_seasonality='auto',            weekly_seasonality='auto', daily_seasonality='auto', holidays=None, seasonality_mode='additive',            seasonality_prior_scale=10.0, holidays_prior_scale=10.0,changepoint_prior_scale=0.05,mcmc_samples=0,interval_width=0.8,            uncertainty_samples=1000, stan_backend=None):        try:            self.prophet = Prophet(growth=growth, changepoints=changepoints, n_changepoints=n_changepoints,                          changepoint_range=changepoint_range, yearly_seasonality=yearly_seasonality,                          weekly_seasonality=weekly_seasonality, daily_seasonality=daily_seasonality,                          holidays=holidays, seasonality_mode=seasonality_mode, seasonality_prior_scale=seasonality_prior_scale,                          holidays_prior_scale=holidays_prior_scale, changepoint_prior_scale=changepoint_prior_scale,                            mcmc_samples=mcmc_samples,interval_width=interval_width,                              uncertainty_samples=uncertainty_samples, stan_backend=stan_backend)            data = df[['date', self.y]].rename(columns={'date': 'ds', self.y: 'y'})            if fit or not os.path.exists(os.path.join(PROJECT_PATH, 'model/pkl', self.code + '_prop.pkl')):                self.prophet.fit(data)                fw = open(os.path.join(PROJECT_PATH, 'model/pkl', self.code + '_prop.pkl'), 'wb')                pickle.dump(self.prophet, fw)                fw.close()            else:                with open(os.path.join(PROJECT_PATH, 'model/pkl', self.code + '_prop.pkl'), 'rb') as fr:                    self.prophet = pickle.load(fr)            self.future = self.prophet.make_future_dataframe(periods=self.periods)            rest = RestDay()            rest_day = rest.get_rest(pd.to_datetime(data['ds'].max()).year, (pd.to_datetime(data['ds'].max()) + datetime.timedelta(days=self.periods)).year)            self.future = self.future[~self.future['ds'].isin(rest_day['ds'])]            self.forecast = self.prophet.predict(self.future)            self.prophet_plot = ProphetPlot(self.title)            if self.show_plot:                self.plot = self.prophet_plot.plot(self.prophet, self.forecast)            if self.show_point:                self.point_plot = self.prophet_plot.plot_point(self.prophet, self.forecast)            if self.show_components:                self.components = self.prophet.plot_components(self.forecast)            self.cross_plot = Page(layout=Page.SimplePageLayout)        except Exception as e:            logger.error(e)            return False        return True    def cross_validation(self, initial='365 days', period='60 days', horizon='60 days'):        try:            self.cv_data = cross_validation(self.prophet, initial = initial, period = period, horizon = horizon)            self.performance = performance_metrics(self.cv_data)            if self.show_cross:                pre_plot = self.prophet_plot.plot(self.prophet, self.cv_data)                cross = self.prophet_plot.plot_cross_validation_metric(self.cv_data, self.metric)                self.cross_plot.add(pre_plot)                self.cross_plot.add(cross)        except Exception as e:            logger.error(e)class XGBModel():    def __init__(self, code, split_date = None, start = '2010-01-01'):        self.code = code        self.start = start        self.split_date = split_date        self.x_train = None        self.y_train = None        self.x_test = None        self.y_test = None        self.model = None        self.feature = None        self.num_col = []        self.cate_col = []        self.fill_data = {}        self.chart = None    def init_data(self):        try:            data = Data(self.code, start=self.start)            all_data = data.get_all_data()            if self.split_date is None:                self.split_date = (pd.to_datetime(all_data['date'].min()) + (pd.to_datetime(all_data['date'].max()) - pd.to_datetime(all_data['date'].min()))/3).strftime('%Y-%m-%d')            unuse = ['code', 'adjustflag', 'tradestatus', 'isST', 'pubDate', 'statYear_x', 'statMonth', 'statYear_y',                     'profitForcastAbstract']            all_data.set_index('date', drop=True, inplace=True)            columns = all_data.columns.tolist()            columns = list(set(columns) - set(unuse))            self.cate_col = ['year', 'month', 'quarter', 'profitForcastType']            self.num_col = list(set(columns) - set(self.cate_col))            all_data = all_data[columns]            all_data = all_data.replace('', np.nan)            for col in self.cate_col:                all_data[col] = all_data[col].astype(str)            for col in self.num_col:                all_data[col] = all_data[col].astype(np.float64)            y = all_data[['close']]            x = all_data.drop('close', axis=1)            x = pd.get_dummies(x)            x = x.dropna(axis=1, how='all')            self.fill_data = x.mean().to_dict()            x = x.fillna(self.fill_data)            self.pre_x = x.loc[x.index.max():]            self.pre_x.rename(index = {x.index.max():(pd.to_datetime(x.index.max()) + datetime.timedelta(days=1)).strftime('%Y-%m-%d')}, inplace = True)            y = y.iloc[1:]            x = x.iloc[:-1]            x.index = y.index            self.feature = x.columns.tolist()            self.x_train = x.loc[:self.split_date]            self.y_train = y.loc[:self.split_date]            self.x_test = x.loc[self.split_date:]            self.y_test = y.loc[self.split_date:]        except Exception as e:            logger.error(e)            return    def fit(self, fit = True, eval_metric = 'mae', verbose = 1, **kwargs):        try:            if fit or not os.path.exists(os.path.join(PROJECT_PATH, 'model/pkl', self.code + '_xgb.pkl')):                self.model = xgb.XGBRegressor(**kwargs)                self.model.fit(self.x_train, self.y_train, eval_set = [(self.x_test, self.y_test)], eval_metric = eval_metric, verbose = verbose)                fw = open(os.path.join(PROJECT_PATH, 'model/pkl', self.code + '_xgb.pkl'), 'wb')                pickle.dump(self.model, fw)                fw.close()            else:                with open(os.path.join(PROJECT_PATH, 'model/pkl', self.code + '_xgb.pkl'), 'rb') as fr:                    self.model = pickle.load(fr)            pre_data = pd.concat([self.x_test, self.pre_x])            result = self.model.predict(pre_data)            result = np.round(result, 2)            plotxgb = PlotXGB()            self.chart = plotxgb.drew(pre_data.index.tolist(), self.y_test['close'].tolist(), result.tolist())        except Exception as e:            logger.error(e)            return    def predict(self, df):        df = df[self.num_col + self.cate_col]        df = df.replace('', np.nan)        for col in self.cate_col:            df[col] = df[col].astype(str)        for col in self.num_col:            df[col] = df[col].astype(np.float64)        df = pd.get_dummies(df)        diff = list(set(self.feature) - set(df.columns.tolist()))        df[diff] = 0        df = df.fillna(self.fill_data)        result = self.model.predict(df)        return resultclass LSTMBuild(nn.Module):    def __init__(self, input_size, hidden_size = 8, num_layers = 5):        super().__init__()        self.LSTM1 = nn.LSTM(input_size, hidden_size, num_layers, bidirectional=False)        self.Linear = nn.Linear(hidden_size, 1)    def forward(self, x):        x, _ = self.LSTM1(x)        s, b, h = x.size()        x = x.view(s * b, h)        x = self.Linear(x)        x = x.view(s, b, -1)        return xclass LSTMModel():    def __init__(self, code, period, start = "2010-01-01", hidden_size = 8, num_layers = 5, batch_size = 50, epoch = 100, n_tep = 5, lr = 1e-2):        self.code = code        self.period = period        self.start = start        self.x_train = None        self.y_train = None        self.x_test = None        self.y_test = None        self.new_test = None        self.model = None        self.stan = None        self.index = []        self.batch_size = batch_size        self.epoch = epoch        self.n_tep = n_tep        self.lr = lr        self.hidden_size = hidden_size        self.num_layers = num_layers    def init_data(self):        input_train = []        output_train = []        data = Data(self.code, start=self.start)        data.get_query_history_k_data_plus()        data = data.query_history_k_data_plus[['date', 'close']]        data.set_index('date', drop=True, inplace=True)        self.stan = StandardScaler()        data = pd.DataFrame(self.stan.fit_transform(data), index=data.index)        for i in range((len(data) // self.period) * self.period - self.period - 1):            x = np.array(data.iloc[i: i + self.period])            y = np.array(data.iloc[i + self.period + 1], np.float64)            self.index.append(data.iloc[i + self.period + 1].name)            input_train.append(x)            output_train.append(y)        input_train = np.array(input_train, np.float64).reshape(-1, 1, self.period)        output_train = np.array(output_train, np.float64)        self.x_train = input_train[0:int(0.8 * len(input_train))]        self.y_train = output_train[0:int(0.8 * len(output_train))]        self.x_test = input_train[int(0.8 * len(input_train)):]        self.y_test = output_train[int(0.8 * len(output_train)):]        self.index = self.index[int(0.8 * len(self.index)):]        self.index.append((pd.to_datetime(self.index[-1]) + datetime.timedelta(days=1)).strftime('%Y-%m-%d'))        self.new_test = np.append(self.x_test,np.array(data.iloc[-self.period:], np.float64).reshape(-1,1,self.period), axis=0)    def early_stop(self, q, loss, step=10):        if len(q) < step:            if len(q) > 0 and q[-1] <= loss:                q.append(loss)            else:                q = [loss]            if len(q) >= step:                return True            else:                return False    def fit(self, fit=True):        if fit or not os.path.exists(os.path.join(PROJECT_PATH, 'model/pkl', self.code + '_lstm.pkl')):            self.model =LSTMBuild(self.period, hidden_size=self.hidden_size,num_layers=self.num_layers)            optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)            lossfun = torch.nn.MSELoss()            q = []            train_losses = []            valid_losses = []            self.model.train()            for i in range(self.epoch):                start = time.time()                outputs = self.model(torch.from_numpy(self.x_train.reshape(-1, 1, self.period)).float())                loss = lossfun(outputs.squeeze(), torch.from_numpy(self.y_train).float().squeeze())                optimizer.zero_grad()                loss.backward()                optimizer.step()                end = time.time()                logger.info('\r' + 'Train epoch: {}/{} [{}{}] {:.2f}% {:.2f}s {:.4f}'.format(i, self.epoch, '>' * int((i + 1) * 50 / self.epoch),                                                                                           ' ' * int((1 - ((i + 1) / self.epoch)) * 50),                                                                                           float((i + 1) / self.epoch * 100),                                                                                           (end - start), loss.item()), end='')                if self.early_stop(q, loss.item()):                    break            torch.save(self.model.state_dict(), os.path.join(PROJECT_PATH, 'model/pkl', self.code + '_lstm.pkl'))        else:            self.model = LSTMBuild(self.period, hidden_size=self.hidden_size,num_layers=self.num_layers)            self.model.load_state_dict(torch.load(os.path.join(PROJECT_PATH, 'model/pkl', self.code + '_lstm.pkl')))        self.model.eval()        result = self.model(torch.from_numpy(self.new_test.reshape(-1,1,self.period)).float())        result = result.view(-1).data.numpy().tolist()        plotlstm = PlotLSTM()        self.chart = plotlstm.drew(self.index, self.stan.inverse_transform(self.y_test.reshape(-1).tolist()).tolist(),                                   self.stan.inverse_transform(result).tolist())